{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from collections import defaultdict\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_string(str_arg):\n",
    "    cleaned_str=re.sub('[^a-zA-Z]+',' ',str_arg,flags=re.IGNORECASE) #every char except alphabets is replacedd\n",
    "    cleaned_str=re.sub('(\\s+)',' ',cleaned_str) #multiple spaces are replaced by single space\n",
    "    cleaned_str=cleaned_str.lower() #converting the cleaned string to lower case\n",
    "    \n",
    "    return cleaned_str # returning the preprocessed string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', 'f', 'cker']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_str=\"Hello 23 F# cker   \"\n",
    "preprocess_string(my_str).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    \n",
    "    def __init__(self,unique_classes):\n",
    "        \n",
    "        self.classes=unique_classes # Constructor is sinply passed with unique number of classes of the training sett\n",
    "        \n",
    "        \n",
    "    def addToBow(self,example,dict_index):\n",
    "        \n",
    "        print(\"Ex 1: \",example)\n",
    "        \n",
    "        if isinstance(example,np.ndarray):\n",
    "            example=example[0]\n",
    "            print(\"is instance executed\")\n",
    "        \n",
    "        print(\"Ex 2: \",example)\n",
    "        print(\"dict indx:\",dict_index)\n",
    "        \n",
    "        for token_word in example.split(): #for every word in preprocessed example\n",
    "            self.bow_dicts[dict_index][token_word]+=1 #increment in its count\n",
    "            \n",
    "            \n",
    "    def train(self,dataset,labels):\n",
    "        self.examples=dataset\n",
    "        self.labels=labels\n",
    "        self.bow_dicts=np.array([defaultdict(lambda:0) for index in range(self.classes.shape[0])])\n",
    "        print(\"Init Bow Dict\",self.bow_dicts)\n",
    "        \n",
    "        if not isinstance(self.examples,np.ndarray): self.examples=np.array(self.examples)\n",
    "        if not isinstance(self.labels,np.ndarray): self.labels=np.array(self.labels)\n",
    "            \n",
    "        #constructing BoW for each category\n",
    "        print(\"Self.Labels\",self.labels==0)\n",
    "        for cat_index,cat in enumerate(self.classes):\n",
    "            all_cat_examples=self.examples[self.labels==cat]\n",
    "            \n",
    "        \n",
    "            cleaned_examples=[preprocess_string(cat_example) for cat_example in all_cat_examples]\n",
    "            print(\"Cleaned Ex 1: \",cleaned_examples)\n",
    "            print(\"Cleaned Ex 1 type: \",type(cleaned_examples))\n",
    "        \n",
    "            cleaned_examples=pd.DataFrame(data=cleaned_examples)\n",
    "            print(\"Cleaned Ex 2: \",cleaned_examples)\n",
    "            print(\"Cleaned Ex 2 type: \",type(cleaned_examples))\n",
    "            \n",
    "            #now costruct BoW of this particular category\n",
    "            np.apply_along_axis(self.addToBow,1,cleaned_examples,cat_index)\n",
    "            \n",
    "        prob_classes=np.empty(self.classes.shape[0])\n",
    "        all_words=[]\n",
    "        cat_word_counts=np.empty(self.classes.shape[0])\n",
    "            \n",
    "        for cat_index,cat in enumerate(self.classes):\n",
    "            #Calculating prior probability p(c) for each class\n",
    "            prob_classes[cat_index]=np.sum(self.labels==cat)/float(self.labels.shape[0]) \n",
    "            \n",
    "            #Calculating total counts of all the words of each class \n",
    "            count=list(self.bow_dicts[cat_index].values())\n",
    "            cat_word_counts[cat_index]=np.sum(np.array(count)) # |v| + 1 is remaining to be added\n",
    "            \n",
    "            #get all words of this category                                \n",
    "            all_words+=self.bow_dicts[cat_index].keys()\n",
    "                \n",
    "        #combine all words of every category & make them unique to get vocabulary -V- of entire training set\n",
    "        \n",
    "        self.vocab=np.unique(np.array(all_words))\n",
    "        self.vocab_length=self.vocab.shape[0]\n",
    "        \n",
    "            \n",
    "        #computing denominator value                                      \n",
    "        denoms=np.array([cat_word_counts[cat_index]+self.vocab_length+1 for cat_index,cat in enumerate(self.classes)])\n",
    "            \n",
    "            \n",
    "        '''\n",
    "        Now that we have everything precomputed as well, its better to organize everything in a tuple \n",
    "        rather than to have a separate list for every thing.\n",
    "            \n",
    "        Every element of self.cats_info has a tuple of values\n",
    "        Each tuple has a dict at index 0, prior probability at index 1, denominator value at index 2\n",
    "        '''\n",
    "        \n",
    "        self.cats_info=[(self.bow_dicts[cat_index],prob_classes[cat_index],denoms[cat_index]) for cat_index,cat in enumerate(self.classes)]                               \n",
    "        self.cats_info=np.array(self.cats_info)\n",
    "            \n",
    "            \n",
    "    def getExampleProb(self,test_example):\n",
    "        likelihood_prob=np.zeros(self.classes.shape[0]) #to store probability w.r.t each clasS\n",
    "        print(\"Likelihood Prob Init\",likelihood_prob)\n",
    "        #finding probability w.r.t each class of the given test example\n",
    "        for cat_index,cat in enumerate(self.classes):\n",
    "            \n",
    "            for test_token in test_example.split(): #split the test example and get p of each test word\n",
    "                print(\"Test token\",test_token)\n",
    "                print(\"Test Ex\",test_example)\n",
    "                #get total count of this test token from it's respective training dict to get numerator value                           \n",
    "                test_token_counts=self.cats_info[cat_index][0].get(test_token,0)+1\n",
    "                    \n",
    "                #now get likelihood of this test_token word                              \n",
    "                test_token_prob=test_token_counts/float(self.cats_info[cat_index][2])\n",
    "                \n",
    "                #remember why taking log? To prevent underflow!\n",
    "                likelihood_prob[cat_index]+=np.log(test_token_prob)\n",
    "                print(\"Likelihood Prob Vals\",likelihood_prob)\n",
    "                \n",
    "        # we have likelihood estimate of the given example against every class but we need posterior probility\n",
    "        post_prob=np.empty(self.classes.shape[0])\n",
    "        print(\"Post Prob Init\",post_prob)\n",
    "        for cat_index,cat in enumerate(self.classes):\n",
    "            post_prob[cat_index]=likelihood_prob[cat_index]+np.log(self.cats_info[cat_index][1])\n",
    "            \n",
    "        return post_prob\n",
    "    \n",
    "    \n",
    "    def test(self,test_set):\n",
    "        \n",
    "        predictions=[] #to store prediction of each test example\n",
    "        for example in test_set: \n",
    "                                              \n",
    "            #preprocess the test example the same way we did for training set exampels                                  \n",
    "            cleaned_example=preprocess_string(example) \n",
    "             \n",
    "            #simply get the posterior probability of every example                                  \n",
    "            post_prob=self.getExampleProb(cleaned_example) #get prob of this example for both classes\n",
    "            \n",
    "            #simply pick the max value and map against self.classes!\n",
    "            predictions.append(self.classes[np.argmax(post_prob)])\n",
    "                \n",
    "        return np.array(predictions) \n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "    def print_data(self):\n",
    "        print(\"Bow Dict\",self.bow_dicts)\n",
    "        print(\"Outer Bow type\",type(self.bow_dicts))\n",
    "        print(\"Inner Bow type\",type(self.bow_dicts[0]))\n",
    "        print(\"Bow Dict Shape\",self.bow_dicts.shape)\n",
    "        print(\"Bow Dict indx:0 \",self.bow_dicts[0])\n",
    "        print(\"Bow Dict indx:1 \",self.bow_dicts[1])\n",
    "        print(\"Self Cats Info\",self.cats_info)\n",
    "        print(\"Self Cats Shape\",self.cats_info.shape)\n",
    "        print(\"Self Cats Type\",type(self.cats_info))\n",
    "        print(\"Vocab Size\",self.vocab_length)\n",
    "        print(\"Vocab \",self.vocab)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = [\"Simply loved it\",\n",
    "    \"Most disgusting food i have ever had\",\n",
    "    \"Stay away, very disgusting food\",\n",
    "     \"Menu is absolutely perfect, loved it!\",\n",
    "    \"A really good value for money\",\n",
    "     \"This is a very good restaurant\",\n",
    "    \"Terrible experience!\",\n",
    "    \"This place has best food\",\n",
    "    \"This place has most pathetic serving food!\"]\n",
    "\n",
    "y = [1,0,0,1,1,1,0,1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "y_labels = np.unique(y)\n",
    "print(type(y_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = NaiveBayes(y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Bow Dict [defaultdict(<function NaiveBayes.train.<locals>.<listcomp>.<lambda> at 0x000001358465F790>, {})\n",
      " defaultdict(<function NaiveBayes.train.<locals>.<listcomp>.<lambda> at 0x000001358465FAF0>, {})]\n",
      "Self.Labels [False  True  True False False False  True False  True]\n",
      "Cleaned Ex 1:  ['most disgusting food i have ever had', 'stay away very disgusting food', 'terrible experience ', 'this place has most pathetic serving food ']\n",
      "Cleaned Ex 1 type:  <class 'list'>\n",
      "Cleaned Ex 2:                                              0\n",
      "0        most disgusting food i have ever had\n",
      "1              stay away very disgusting food\n",
      "2                        terrible experience \n",
      "3  this place has most pathetic serving food \n",
      "Cleaned Ex 2 type:  <class 'pandas.core.frame.DataFrame'>\n",
      "Ex 1:  ['most disgusting food i have ever had']\n",
      "is instance executed\n",
      "Ex 2:  most disgusting food i have ever had\n",
      "dict indx: 0\n",
      "Ex 1:  ['stay away very disgusting food']\n",
      "is instance executed\n",
      "Ex 2:  stay away very disgusting food\n",
      "dict indx: 0\n",
      "Ex 1:  ['terrible experience ']\n",
      "is instance executed\n",
      "Ex 2:  terrible experience \n",
      "dict indx: 0\n",
      "Ex 1:  ['this place has most pathetic serving food ']\n",
      "is instance executed\n",
      "Ex 2:  this place has most pathetic serving food \n",
      "dict indx: 0\n",
      "Cleaned Ex 1:  ['simply loved it', 'menu is absolutely perfect loved it ', 'a really good value for money', 'this is a very good restaurant', 'this place has best food']\n",
      "Cleaned Ex 1 type:  <class 'list'>\n",
      "Cleaned Ex 2:                                        0\n",
      "0                       simply loved it\n",
      "1  menu is absolutely perfect loved it \n",
      "2         a really good value for money\n",
      "3        this is a very good restaurant\n",
      "4              this place has best food\n",
      "Cleaned Ex 2 type:  <class 'pandas.core.frame.DataFrame'>\n",
      "Ex 1:  ['simply loved it']\n",
      "is instance executed\n",
      "Ex 2:  simply loved it\n",
      "dict indx: 1\n",
      "Ex 1:  ['menu is absolutely perfect loved it ']\n",
      "is instance executed\n",
      "Ex 2:  menu is absolutely perfect loved it \n",
      "dict indx: 1\n",
      "Ex 1:  ['a really good value for money']\n",
      "is instance executed\n",
      "Ex 2:  a really good value for money\n",
      "dict indx: 1\n",
      "Ex 1:  ['this is a very good restaurant']\n",
      "is instance executed\n",
      "Ex 2:  this is a very good restaurant\n",
      "dict indx: 1\n",
      "Ex 1:  ['this place has best food']\n",
      "is instance executed\n",
      "Ex 2:  this place has best food\n",
      "dict indx: 1\n"
     ]
    }
   ],
   "source": [
    "nb.train(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bow Dict [defaultdict(<function NaiveBayes.train.<locals>.<listcomp>.<lambda> at 0x000001358465F790>, {'most': 2, 'disgusting': 2, 'food': 3, 'i': 1, 'have': 1, 'ever': 1, 'had': 1, 'stay': 1, 'away': 1, 'very': 1, 'terrible': 1, 'experience': 1, 'this': 1, 'place': 1, 'has': 1, 'pathetic': 1, 'serving': 1})\n",
      " defaultdict(<function NaiveBayes.train.<locals>.<listcomp>.<lambda> at 0x000001358465FAF0>, {'simply': 1, 'loved': 2, 'it': 2, 'menu': 1, 'is': 2, 'absolutely': 1, 'perfect': 1, 'a': 2, 'really': 1, 'good': 2, 'value': 1, 'for': 1, 'money': 1, 'this': 2, 'very': 1, 'restaurant': 1, 'place': 1, 'has': 1, 'best': 1, 'food': 1})]\n",
      "Outer Bow type <class 'numpy.ndarray'>\n",
      "Inner Bow type <class 'collections.defaultdict'>\n",
      "Bow Dict Shape (2,)\n",
      "Bow Dict indx:0  defaultdict(<function NaiveBayes.train.<locals>.<listcomp>.<lambda> at 0x000001358465F790>, {'most': 2, 'disgusting': 2, 'food': 3, 'i': 1, 'have': 1, 'ever': 1, 'had': 1, 'stay': 1, 'away': 1, 'very': 1, 'terrible': 1, 'experience': 1, 'this': 1, 'place': 1, 'has': 1, 'pathetic': 1, 'serving': 1})\n",
      "Bow Dict indx:1  defaultdict(<function NaiveBayes.train.<locals>.<listcomp>.<lambda> at 0x000001358465FAF0>, {'simply': 1, 'loved': 2, 'it': 2, 'menu': 1, 'is': 2, 'absolutely': 1, 'perfect': 1, 'a': 2, 'really': 1, 'good': 2, 'value': 1, 'for': 1, 'money': 1, 'this': 2, 'very': 1, 'restaurant': 1, 'place': 1, 'has': 1, 'best': 1, 'food': 1})\n",
      "Self Cats Info [[defaultdict(<function NaiveBayes.train.<locals>.<listcomp>.<lambda> at 0x000001358465F790>, {'most': 2, 'disgusting': 2, 'food': 3, 'i': 1, 'have': 1, 'ever': 1, 'had': 1, 'stay': 1, 'away': 1, 'very': 1, 'terrible': 1, 'experience': 1, 'this': 1, 'place': 1, 'has': 1, 'pathetic': 1, 'serving': 1})\n",
      "  0.4444444444444444 54.0]\n",
      " [defaultdict(<function NaiveBayes.train.<locals>.<listcomp>.<lambda> at 0x000001358465FAF0>, {'simply': 1, 'loved': 2, 'it': 2, 'menu': 1, 'is': 2, 'absolutely': 1, 'perfect': 1, 'a': 2, 'really': 1, 'good': 2, 'value': 1, 'for': 1, 'money': 1, 'this': 2, 'very': 1, 'restaurant': 1, 'place': 1, 'has': 1, 'best': 1, 'food': 1})\n",
      "  0.5555555555555556 59.0]]\n",
      "Self Cats Shape (2, 3)\n",
      "Self Cats Type <class 'numpy.ndarray'>\n",
      "Vocab Size 32\n",
      "Vocab  ['a' 'absolutely' 'away' 'best' 'disgusting' 'ever' 'experience' 'food'\n",
      " 'for' 'good' 'had' 'has' 'have' 'i' 'is' 'it' 'loved' 'menu' 'money'\n",
      " 'most' 'pathetic' 'perfect' 'place' 'really' 'restaurant' 'serving'\n",
      " 'simply' 'stay' 'terrible' 'this' 'value' 'very']\n"
     ]
    }
   ],
   "source": [
    "nb.print_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likelihood Prob Init [0. 0.]\n",
      "Test token very\n",
      "Test Ex very good food and service\n",
      "Likelihood Prob Vals [-3.29583687  0.        ]\n",
      "Test token good\n",
      "Test Ex very good food and service\n",
      "Likelihood Prob Vals [-7.28482091  0.        ]\n",
      "Test token food\n",
      "Test Ex very good food and service\n",
      "Likelihood Prob Vals [-9.8875106  0.       ]\n",
      "Test token and\n",
      "Test Ex very good food and service\n",
      "Likelihood Prob Vals [-13.87649464   0.        ]\n",
      "Test token service\n",
      "Test Ex very good food and service\n",
      "Likelihood Prob Vals [-17.86547869   0.        ]\n",
      "Test token very\n",
      "Test Ex very good food and service\n",
      "Likelihood Prob Vals [-17.86547869  -3.38439026]\n",
      "Test token good\n",
      "Test Ex very good food and service\n",
      "Likelihood Prob Vals [-17.86547869  -6.36331542]\n",
      "Test token food\n",
      "Test Ex very good food and service\n",
      "Likelihood Prob Vals [-17.86547869  -9.74770568]\n",
      "Test token and\n",
      "Test Ex very good food and service\n",
      "Likelihood Prob Vals [-17.86547869 -13.82524313]\n",
      "Test token service\n",
      "Test Ex very good food and service\n",
      "Likelihood Prob Vals [-17.86547869 -17.90278057]\n",
      "Post Prob Init [17.86547869 17.90278057]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = [\"very good food and service\"]\n",
    "nb.test(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function <lambda> at 0x00000217C3D2DC10>, {'a': 1, 'b': 2})\n",
      "[1, 2]\n",
      "['a', 'b']\n",
      "<class 'collections.defaultdict'>\n"
     ]
    }
   ],
   "source": [
    "# = {\"b\":2,\"c\":3}\n",
    "d = defaultdict(lambda:\"Not Present\")\n",
    "d[\"a\"]=1\n",
    "d[\"b\"]=2\n",
    "print(d)\n",
    "l1 = list(d.values())\n",
    "print(l1)\n",
    "l2 = list(d)\n",
    "print(l2)\n",
    "print(type(d))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 20news dataset. This may take a few minutes.\n",
      "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
     ]
    }
   ],
   "source": [
    "categories=['alt.atheism', 'soc.religion.christian','comp.graphics', 'sci.med'] \n",
    "newsgroups_train=fetch_20newsgroups(subset='train',categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=newsgroups_train.data #getting all trainign examples\n",
    "train_labels=newsgroups_train.target #getting training labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Training Examples:  2257\n",
      "Total Number of Training Labels:  2257\n"
     ]
    }
   ],
   "source": [
    "print (\"Total Number of Training Examples: \",len(train_data)) # Outputs -> Total Number of Training Examples:  2257\n",
    "print (\"Total Number of Training Labels: \",len(train_labels)) # Outputs -> #Total Number of Training Labels:  2257"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- Training In Progress --------------------\n"
     ]
    }
   ],
   "source": [
    "nb=NaiveBayes(np.unique(train_labels)) #instantiate a NB class object\n",
    "print (\"---------------- Training In Progress --------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Bow Dict [defaultdict(<function NaiveBayes.train.<locals>.<listcomp>.<lambda> at 0x000001F59D840430>, {})\n",
      " defaultdict(<function NaiveBayes.train.<locals>.<listcomp>.<lambda> at 0x000001F59D840D30>, {})\n",
      " defaultdict(<function NaiveBayes.train.<locals>.<listcomp>.<lambda> at 0x000001F59D840EE0>, {})\n",
      " defaultdict(<function NaiveBayes.train.<locals>.<listcomp>.<lambda> at 0x000001F59D840670>, {})]\n",
      "----------------- Training Completed ---------------------\n"
     ]
    }
   ],
   "source": [
    "nb.train(train_data,train_labels) #start tarining by calling the train function\n",
    "print ('----------------- Training Completed ---------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Test Examples:  1502\n",
      "Number of Test Labels:  1502\n"
     ]
    }
   ],
   "source": [
    "newsgroups_test=fetch_20newsgroups(subset='test',categories=categories) #loading test data\n",
    "test_data=newsgroups_test.data #get test set examples\n",
    "test_labels=newsgroups_test.target #get test set labels\n",
    "\n",
    "print (\"Number of Test Examples: \",len(test_data)) # Output : Number of Test Examples:  1502\n",
    "print (\"Number of Test Labels: \",len(test_labels)) # Output : Number of Test Labels:  1502"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Examples:  1502\n",
      "Test Set Accuracy:  93.87483355525966 %\n"
     ]
    }
   ],
   "source": [
    "pclasses=nb.test(test_data) #get predcitions for test set\n",
    "\n",
    "#check how many predcitions actually match original test labels\n",
    "test_acc=np.sum(pclasses==test_labels)/float(test_labels.shape[0]) \n",
    "\n",
    "print (\"Test Set Examples: \",test_labels.shape[0]) # Outputs : Test Set Examples:  1502\n",
    "print (\"Test Set Accuracy: \",test_acc*100,\"%\") # Outputs : Test Set Accuracy:  93.8748335553 %\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.apply_along_axis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
